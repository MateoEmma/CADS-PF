{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de recomendacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de la libreria Surprice, usamos el algoritmo de KNnWhitMeans, que en su caja negra lo que hace es construir una matriz a partir de los ratings puestos por los usuario\n",
    "sobre los productos. Calcula la distancia por coseno entre vectores(rating) para ponerle valor numerico a la relacion para poder recomendar en base a los productos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession \n",
    "import numpy as np\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, udf, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, FloatType\n",
    "from surprise import SVD, SVDpp, NMF, SlopeOne, CoClustering, KNNBaseline, KNNWithZScore, KNNWithMeans, KNNBasic, BaselineOnly, NormalPredictor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iniciamos sesion en Spark\n",
    "spark = SparkSession.builder.appName('sent').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leemos el dataset\n",
    "dfspark = spark.read.json('../common/data/reviews_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos una funcion que va a servir para crear un columna nueva\n",
    "def prom_rating(val, val1):\n",
    "    ''' Calcula el valor pormedio entre dos valores '''\n",
    "    return (val + val1)/2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_new = udf(prom_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una columna nueva que promedia el ranking dado por el usuario y el establecido por el analizis de testo\n",
    "dfspark = dfspark.withColumn(\"average_ranq\", col_new(col(\"sentiment\"), col('rating')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccionamos los campos a utilizar\n",
    "dfspark1 = dfspark.select('productId', 'reviewerId', 'average_ranq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista de los productos con mas reviews\n",
    "mejores_productos_más_calificados = dfspark.groupBy(\"productId\").count().sort(F.col(\"count\").desc()).limit(5000)\n",
    "productos = mejores_productos_más_calificados.select('productId').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtramos el dataframe con los productos con mas reviews\n",
    "dfsparkFiltro = dfspark1.filter((dfspark.productId).isin(productos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiamos los nombres de los campos para que el modelo los pueda procesar\n",
    "modelo = dfsparkFiltro.withColumnRenamed('reviewerId', 'user').withColumnRenamed('productId','item').withColumnRenamed('average_ranq', 'rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiamos el tipo de dato de la columna 'rating'\n",
    "modelo = modelo.withColumn('rating', F.col('rating').cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos dos listas\n",
    "users = modelo.select('user').distinct()\n",
    "items = modelo.select('item').distinct()\n",
    "users = users.select('user').rdd.flatMap(lambda x: x).collect()\n",
    "items = items.select('item').rdd.flatMap(lambda x: x).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fortalecemos la conexion de PySpark con Pandas\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pasamos el dataframe a Pandas\n",
    "df_pd = modelo.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el modelo\n",
    "sim_options = {\"name\": \"cosine\", \"user_based\": False,}\n",
    "\n",
    "algoritmo = KNNWithMeans(sim_options=sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_n = Dataset.load_from_df(df_pd[[\"user\", \"item\", \"rating\"]], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos la matriz de entrenamiento\n",
    "trainingSet = data_n.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x7f0f4acf1dd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algoritmo.fit(trainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 'B00JTKDTLE'],\n",
       " [5, 'B00JV858HM'],\n",
       " [5, 'B00JVZ0DQG'],\n",
       " [5, 'B00KWVZ750'],\n",
       " [5, 'BT00DDVMVQ']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#El modelo devuelvo los 5 productos mas recomendados para un usuario x\n",
    "recomend = []\n",
    "usuario = 'A53MRKZW1IM66'\n",
    "for item in items:\n",
    "    p1 = algoritmo.predict(usuario, item[:50])\n",
    "    if p1.est > 1:\n",
    "        p2 = [p1.est , p1.iid]\n",
    "        recomend.append(p2)\n",
    "recomend.sort()\n",
    "recomend[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_id_to_name(id):\n",
    "    name = dfspark_prod.filter((dfspark_prod.productId)==id).collect()[0][4]    \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = 0\n",
    "while con <= 4:\n",
    "    calification = recomend[-5:][con][0]\n",
    "    prod_id = recomend[-5:][con][1]\n",
    "    print(f'Para el usuario {usuario} la recomendacion es : {item_id_to_name(prod_id)}')\n",
    "    con += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspark_prod = spark.read.json('../common/data/products_etl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre = dfspark_prod.filter((dfspark1.productId).isin([recomend[1], recomend[3], recomend[5], recomend[7]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre.select('categories').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b8cdd4f9a101fdd4557da0745686d41d9a3acecbeb7c45458d61a0a0b7bf82a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
